{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CIFAR10CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR10CNN, self).__init__()\n",
    "        # 3 input channels (RGB), 32x32 images\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)  # 32x32 -> 32x32\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1) # 32x32 -> 32x32\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, padding=1) # 32x32 -> 32x32\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 32x32 -> 16x16 -> 8x8\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        # After 3 conv layers and 2 pool layers: 64 channels, 8x8 feature maps\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # 32x32 -> 16x16\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # 16x16 -> 8x8\n",
    "        x = F.relu(self.conv3(x))             # 8x8 -> 8x8\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def get_model_params(model):\n",
    "    return {name: param.clone() for name, param in model.state_dict().items()}\n",
    "\n",
    "def set_model_params(model, params):\n",
    "    model.load_state_dict(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class Client:\n",
    "    def __init__(self, client_id, train_data, test_data, is_malicious=False, target_label=None):\n",
    "        self.client_id = client_id\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.is_malicious = is_malicious\n",
    "        self.target_label = target_label\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "    def add_backdoor_trigger(self, image):\n",
    "        \"\"\"Add a '+' shaped trigger to the image at a random position\"\"\"\n",
    "        img = deepcopy(image)\n",
    "        h, w = img.shape[1:]\n",
    "        \n",
    "        # Random position for the trigger\n",
    "        x = np.random.randint(2, w-3)\n",
    "        y = np.random.randint(2, h-3)\n",
    "        \n",
    "        # Random size for the trigger\n",
    "        trigger_w = np.random.randint(2, 4)\n",
    "        trigger_h = np.random.randint(2, 4)\n",
    "        \n",
    "        # Add horizontal line\n",
    "        img[0, y:y+trigger_h, x-trigger_w:x+trigger_w] = 1.0\n",
    "        # Add vertical line\n",
    "        img[0, y-trigger_w:y+trigger_w, x:x+trigger_h] = 1.0\n",
    "        \n",
    "        return img\n",
    "\n",
    "    def poison_dataset(self):\n",
    "        \"\"\"Poison the training data with backdoor triggers\"\"\"\n",
    "        if not self.is_malicious:\n",
    "            return self.train_data\n",
    "            \n",
    "        poisoned_images = []\n",
    "        poisoned_labels = []\n",
    "        \n",
    "        for img, label in self.train_data:\n",
    "            if np.random.random() < 0.5:  # Poison 50% of the data\n",
    "                img = self.add_backdoor_trigger(img)\n",
    "                label = self.target_label\n",
    "            poisoned_images.append(img)\n",
    "            poisoned_labels.append(label)\n",
    "            \n",
    "        return TensorDataset(torch.stack(poisoned_images), torch.tensor(poisoned_labels))\n",
    "\n",
    "    def train(self, model, epochs=1, batch_size=32):\n",
    "        \"\"\"Train the model on client's data\"\"\"\n",
    "        model.train()\n",
    "        model.to(self.device)\n",
    "        \n",
    "        # Get potentially poisoned dataset\n",
    "        train_data = self.poison_dataset() if self.is_malicious else self.train_data\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = F.nll_loss(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        return {name: param.clone().detach() for name, param in model.state_dict().items()}\n",
    "\n",
    "    def test(self, model):\n",
    "        \"\"\"Test the model on client's test data\"\"\"\n",
    "        model.eval()\n",
    "        model.to(self.device)\n",
    "        \n",
    "        test_loader = DataLoader(self.test_data, batch_size=32, shuffle=False)\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = model(data)\n",
    "                test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += pred.eq(target).sum().item()\n",
    "                total += target.size(0)\n",
    "                \n",
    "        test_loss /= total\n",
    "        accuracy = 100. * correct / total\n",
    "        \n",
    "        return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class Server:\n",
    "    def __init__(self, model, clients, use_defense=True, similarity_threshold=0.9):\n",
    "        self.model = model\n",
    "        self.clients = clients\n",
    "        self.use_defense = use_defense\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        # Track actual malicious clients\n",
    "        self.malicious_client_ids = {client.client_id for client in clients if client.is_malicious}\n",
    "\n",
    "    def calculate_detection_metrics(self, detected_clients):\n",
    "        \"\"\"Calculate detection performance metrics\"\"\"\n",
    "        true_positives = len(detected_clients & self.malicious_client_ids)\n",
    "        false_positives = len(detected_clients - self.malicious_client_ids)\n",
    "        false_negatives = len(self.malicious_client_ids - detected_clients)\n",
    "        true_negatives = len({client.client_id for client in self.clients} - \n",
    "                           detected_clients - \n",
    "                           self.malicious_client_ids)\n",
    "\n",
    "        detection_rate = true_positives / len(self.malicious_client_ids) if self.malicious_client_ids else 0\n",
    "        false_positive_rate = false_positives / (false_positives + true_negatives) if (false_positives + true_negatives) > 0 else 0\n",
    "        precision = true_positives / len(detected_clients) if detected_clients else 0\n",
    "\n",
    "        return {\n",
    "            'true_positives': true_positives,\n",
    "            'false_positives': false_positives,\n",
    "            'false_negatives': false_negatives,\n",
    "            'true_negatives': true_negatives,\n",
    "            'detection_rate': detection_rate,\n",
    "            'false_positive_rate': false_positive_rate,\n",
    "            'precision': precision,\n",
    "            'total_malicious': len(self.malicious_client_ids),\n",
    "            'total_detected': len(detected_clients),\n",
    "            'detected_clients': detected_clients,\n",
    "            'actual_malicious': self.malicious_client_ids\n",
    "        }\n",
    "\n",
    "    def fools_gold_defense(self, updates):\n",
    "        \"\"\"Implement Fool's Gold defense mechanism with detailed detection metrics\"\"\"\n",
    "        if not self.use_defense:\n",
    "            return {i: 1.0 for i in range(len(updates))}, None\n",
    "            \n",
    "        # Convert updates to vectors\n",
    "        update_vectors = []\n",
    "        for update in updates:\n",
    "            vector = []\n",
    "            for param in update.values():\n",
    "                vector.extend(param.cpu().numpy().flatten())\n",
    "            update_vectors.append(vector)\n",
    "            \n",
    "        update_vectors = np.array(update_vectors)\n",
    "        \n",
    "        # Compute pairwise similarities\n",
    "        similarities = cosine_similarity(update_vectors)\n",
    "        \n",
    "        # Initialize weights and track detected malicious clients\n",
    "        weights = np.ones(len(updates))\n",
    "        detected_clients = set()\n",
    "        \n",
    "        # Detect potentially malicious clients based on similarity\n",
    "        for i in range(len(updates)):\n",
    "            for j in range(len(updates)):\n",
    "                if i != j and similarities[i][j] > self.similarity_threshold:\n",
    "                    weights[i] *= 0.5\n",
    "                    detected_clients.add(self.clients[i].client_id)\n",
    "                    \n",
    "        # Normalize weights\n",
    "        if np.sum(weights) > 0:\n",
    "            weights = weights / np.sum(weights)\n",
    "        else:\n",
    "            weights = np.ones(len(updates)) / len(updates)\n",
    "        \n",
    "        # Calculate detection metrics\n",
    "        detection_metrics = self.calculate_detection_metrics(detected_clients)\n",
    "        \n",
    "        return {i: float(w) for i, w in enumerate(weights)}, detection_metrics\n",
    "\n",
    "    def aggregate_updates(self, client_updates):\n",
    "        \"\"\"Aggregate updates using weighted average\"\"\"\n",
    "        weights, detection_metrics = self.fools_gold_defense(client_updates)\n",
    "        \n",
    "        aggregated_params = {}\n",
    "        for name, param in client_updates[0].items():\n",
    "            aggregated_params[name] = torch.zeros_like(param)\n",
    "            for client_idx, update in enumerate(client_updates):\n",
    "                aggregated_params[name] += update[name] * weights[client_idx]\n",
    "                \n",
    "        return aggregated_params, detection_metrics\n",
    "\n",
    "    def train_round(self, local_epochs=5):\n",
    "        \"\"\"Conduct one round of federated training\"\"\"\n",
    "        global_params = get_model_params(self.model)\n",
    "        client_updates = []\n",
    "    \n",
    "        for client in self.clients:\n",
    "            set_model_params(self.model, global_params)\n",
    "            client_update = client.train(self.model, epochs=local_epochs)\n",
    "            client_updates.append(client_update)\n",
    "    \n",
    "        # Get aggregated updates and detection metrics\n",
    "        aggregated_update, detection_metrics = self.aggregate_updates(client_updates)\n",
    "    \n",
    "        # Update global model\n",
    "        set_model_params(self.model, aggregated_update)\n",
    "    \n",
    "        # Get evaluation metrics\n",
    "        loss, accuracy = self.evaluate()\n",
    "    \n",
    "        # Always return three values: loss, accuracy, and detection_metrics\n",
    "        # If defense is off, detection_metrics will be None\n",
    "        return loss, accuracy, detection_metrics\n",
    "    def evaluate(self):\n",
    "        \"\"\"Evaluate model on all clients' test data\"\"\"\n",
    "        total_loss = 0\n",
    "        total_accuracy = 0\n",
    "        \n",
    "        for client in self.clients:\n",
    "            loss, accuracy = client.test(self.model)\n",
    "            total_loss += loss\n",
    "            total_accuracy += accuracy\n",
    "            \n",
    "        avg_loss = total_loss / len(self.clients)\n",
    "        avg_accuracy = total_accuracy / len(self.clients)\n",
    "        \n",
    "        return avg_loss, avg_accuracy\n",
    "\n",
    "    def evaluate_backdoor(self, target_label):\n",
    "        \"\"\"Evaluate backdoor attack success rate\"\"\"\n",
    "        self.model.eval()\n",
    "        total = 0\n",
    "        success = 0\n",
    "        \n",
    "        for client in self.clients:\n",
    "            if client.is_malicious:\n",
    "                with torch.no_grad():\n",
    "                    for data, _ in client.test_data:\n",
    "                        poisoned_data = client.add_backdoor_trigger(data.clone())\n",
    "                        poisoned_data = poisoned_data.unsqueeze(0).to(self.device)\n",
    "                        output = self.model(poisoned_data)\n",
    "                        pred = output.argmax(dim=1)\n",
    "                        success += (pred == target_label).sum().item()\n",
    "                        total += 1\n",
    "    \n",
    "        if total == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return 100.0 * success / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-15 11:45:12,329 - INFO - Starting experiments with Fool's Gold defense...\n",
      "2025-02-15 11:45:12,330 - INFO - Starting experiment with 20.0% malicious clients\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-15 11:45:14,057 - INFO - Number of malicious clients: 2\n",
      "2025-02-15 11:46:08,555 - INFO - \n",
      "Round 0:\n",
      "2025-02-15 11:46:08,556 - INFO - Loss = 1.6222, Accuracy = 50.90%\n",
      "2025-02-15 11:46:08,556 - INFO - \n",
      "Detection Metrics for Round 0:\n",
      "2025-02-15 11:46:08,557 - INFO - True Positives: 2\n",
      "2025-02-15 11:46:08,557 - INFO - False Positives: 0\n",
      "2025-02-15 11:46:08,557 - INFO - False Negatives: 0\n",
      "2025-02-15 11:46:08,557 - INFO - True Negatives: 8\n",
      "2025-02-15 11:46:08,558 - INFO - Detection Rate: 100.00%\n",
      "2025-02-15 11:46:08,558 - INFO - False Positive Rate: 0.00%\n",
      "2025-02-15 11:46:08,558 - INFO - Precision: 100.00%\n",
      "2025-02-15 11:46:08,559 - INFO - Total Malicious Clients: 2\n",
      "2025-02-15 11:46:08,559 - INFO - Total Detected Clients: 2\n",
      "2025-02-15 11:46:08,559 - INFO - Detected Client IDs: [0, 1]\n",
      "2025-02-15 11:46:08,559 - INFO - Actual Malicious Client IDs: [0, 1]\n",
      "\n",
      "2025-02-15 11:46:09,643 - INFO - Backdoor Success Rate = 8.70%\n",
      "2025-02-15 11:47:01,600 - INFO - \n",
      "Round 1:\n",
      "2025-02-15 11:47:01,601 - INFO - Loss = 1.1255, Accuracy = 61.72%\n",
      "2025-02-15 11:47:01,601 - INFO - \n",
      "Detection Metrics for Round 1:\n",
      "2025-02-15 11:47:01,601 - INFO - True Positives: 0\n",
      "2025-02-15 11:47:01,602 - INFO - False Positives: 0\n",
      "2025-02-15 11:47:01,602 - INFO - False Negatives: 2\n",
      "2025-02-15 11:47:01,602 - INFO - True Negatives: 8\n",
      "2025-02-15 11:47:01,603 - INFO - Detection Rate: 0.00%\n",
      "2025-02-15 11:47:01,603 - INFO - False Positive Rate: 0.00%\n",
      "2025-02-15 11:47:01,603 - INFO - Precision: 0.00%\n",
      "2025-02-15 11:47:01,604 - INFO - Total Malicious Clients: 2\n",
      "2025-02-15 11:47:01,604 - INFO - Total Detected Clients: 0\n",
      "2025-02-15 11:47:01,604 - INFO - Detected Client IDs: []\n",
      "2025-02-15 11:47:01,604 - INFO - Actual Malicious Client IDs: [0, 1]\n",
      "\n",
      "2025-02-15 11:47:02,673 - INFO - Backdoor Success Rate = 11.05%\n",
      "2025-02-15 11:47:53,258 - INFO - \n",
      "Round 2:\n",
      "2025-02-15 11:47:53,259 - INFO - Loss = 0.9581, Accuracy = 67.01%\n",
      "2025-02-15 11:47:53,259 - INFO - \n",
      "Detection Metrics for Round 2:\n",
      "2025-02-15 11:47:53,259 - INFO - True Positives: 0\n",
      "2025-02-15 11:47:53,260 - INFO - False Positives: 0\n",
      "2025-02-15 11:47:53,260 - INFO - False Negatives: 2\n",
      "2025-02-15 11:47:53,260 - INFO - True Negatives: 8\n",
      "2025-02-15 11:47:53,260 - INFO - Detection Rate: 0.00%\n",
      "2025-02-15 11:47:53,261 - INFO - False Positive Rate: 0.00%\n",
      "2025-02-15 11:47:53,261 - INFO - Precision: 0.00%\n",
      "2025-02-15 11:47:53,261 - INFO - Total Malicious Clients: 2\n",
      "2025-02-15 11:47:53,261 - INFO - Total Detected Clients: 0\n",
      "2025-02-15 11:47:53,262 - INFO - Detected Client IDs: []\n",
      "2025-02-15 11:47:53,262 - INFO - Actual Malicious Client IDs: [0, 1]\n",
      "\n",
      "2025-02-15 11:47:54,354 - INFO - Backdoor Success Rate = 11.90%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def setup_logging():\n",
    "    \"\"\"Setup logging configuration\"\"\"\n",
    "    # Create logs directory if it doesn't exist\n",
    "    if not os.path.exists('logs'):\n",
    "        os.makedirs('logs')\n",
    "    \n",
    "    # Create a timestamp for the log file\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    log_filename = f'logs/federated_training_{timestamp}.log'\n",
    "    \n",
    "    # Configure logging\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_filename),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "def load_and_split_data(num_clients):\n",
    "    \"\"\"Load CIFAR10 dataset and split it among clients\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    ])\n",
    "    \n",
    "    dataset = datasets.CIFAR10('./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.CIFAR10('./data', train=False, transform=transform)\n",
    "    \n",
    "    # Split training data among clients\n",
    "    data_per_client = len(dataset) // num_clients\n",
    "    client_datasets = random_split(dataset, [data_per_client] * num_clients)\n",
    "    \n",
    "    # Split test data among clients\n",
    "    test_per_client = len(test_dataset) // num_clients\n",
    "    client_test_datasets = random_split(test_dataset, [test_per_client] * num_clients)\n",
    "    \n",
    "    return client_datasets, client_test_datasets\n",
    "\n",
    "def log_detection_metrics(logger, detection_metrics, round_num):\n",
    "    \"\"\"Log detailed detection metrics\"\"\"\n",
    "    if detection_metrics:  # Only log if detection metrics are available\n",
    "        logger.info(f\"\\nDetection Metrics for Round {round_num}:\")\n",
    "        logger.info(f\"True Positives: {detection_metrics['true_positives']}\")\n",
    "        logger.info(f\"False Positives: {detection_metrics['false_positives']}\")\n",
    "        logger.info(f\"False Negatives: {detection_metrics['false_negatives']}\")\n",
    "        logger.info(f\"True Negatives: {detection_metrics['true_negatives']}\")\n",
    "        logger.info(f\"Detection Rate: {detection_metrics['detection_rate']*100:.2f}%\")\n",
    "        logger.info(f\"False Positive Rate: {detection_metrics['false_positive_rate']*100:.2f}%\")\n",
    "        logger.info(f\"Precision: {detection_metrics['precision']*100:.2f}%\")\n",
    "        logger.info(f\"Total Malicious Clients: {detection_metrics['total_malicious']}\")\n",
    "        logger.info(f\"Total Detected Clients: {detection_metrics['total_detected']}\")\n",
    "        logger.info(f\"Detected Client IDs: {sorted(detection_metrics['detected_clients'])}\")\n",
    "        logger.info(f\"Actual Malicious Client IDs: {sorted(detection_metrics['actual_malicious'])}\\n\")\n",
    "\n",
    "def run_experiment(num_clients, malicious_percentage, logger, target_label=7, num_rounds=10, local_epochs=5, use_defense=True):\n",
    "    \"\"\"Run federated learning experiment with specified percentage of malicious clients\"\"\"\n",
    "    logger.info(f\"Starting experiment with {malicious_percentage*100}% malicious clients\")\n",
    "    client_datasets, client_test_datasets = load_and_split_data(num_clients)\n",
    "    \n",
    "    num_malicious = int(num_clients * malicious_percentage)\n",
    "    logger.info(f\"Number of malicious clients: {num_malicious}\")\n",
    "    \n",
    "    clients = []\n",
    "    for i in range(num_clients):\n",
    "        is_malicious = i < num_malicious\n",
    "        client = Client(\n",
    "            client_id=i,\n",
    "            train_data=client_datasets[i],\n",
    "            test_data=client_test_datasets[i],\n",
    "            is_malicious=is_malicious,\n",
    "            target_label=target_label if is_malicious else None\n",
    "        )\n",
    "        clients.append(client)\n",
    "    \n",
    "    model = CIFAR10CNN()\n",
    "    server = Server(model, clients, use_defense=use_defense)\n",
    "    \n",
    "    results = []\n",
    "    for round_num in range(num_rounds):\n",
    "        # Now properly unpacking all three values\n",
    "        loss, accuracy, detection_metrics = server.train_round(local_epochs=local_epochs)\n",
    "        \n",
    "        # Log training progress\n",
    "        logger.info(f\"\\nRound {round_num}:\")\n",
    "        logger.info(f\"Loss = {loss:.4f}, Accuracy = {accuracy:.2f}%\")\n",
    "        \n",
    "        # Log detection metrics if defense is enabled\n",
    "        if use_defense and detection_metrics is not None:\n",
    "            log_detection_metrics(logger, detection_metrics, round_num)\n",
    "        \n",
    "        # Test backdoor success rate\n",
    "        backdoor_success = 0\n",
    "        if num_malicious > 0:\n",
    "            backdoor_success = server.evaluate_backdoor(target_label)\n",
    "            logger.info(f\"Backdoor Success Rate = {backdoor_success:.2f}%\")\n",
    "        \n",
    "        results.append({\n",
    "            'round': round_num,\n",
    "            'loss': loss,\n",
    "            'accuracy': accuracy,\n",
    "            'malicious_percentage': malicious_percentage,\n",
    "            'backdoor_success_rate': backdoor_success,\n",
    "            'detection_metrics': detection_metrics\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "def main():\n",
    "    \"\"\"Run experiments with increasing percentages of malicious clients\"\"\"\n",
    "    # Setup logging\n",
    "    logger = setup_logging()\n",
    "    \n",
    "    num_clients = 10\n",
    "    malicious_percentages = [0.2, 0.3, 0.4, 0.5]\n",
    "    all_results = []\n",
    "    \n",
    "    # Experiment with defense on\n",
    "    logger.info(\"Starting experiments with Fool's Gold defense...\")\n",
    "    for percentage in malicious_percentages:\n",
    "        try:\n",
    "            results = run_experiment(\n",
    "                num_clients=num_clients,\n",
    "                malicious_percentage=percentage,\n",
    "                logger=logger,\n",
    "                use_defense=True\n",
    "            )\n",
    "            all_results.extend(results)\n",
    "            logger.info(f\"Completed experiment with {percentage*100}% malicious clients (defense ON)\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in experiment with {percentage*100}% malicious clients: {str(e)}\")\n",
    "    \n",
    "    # Experiment with defense\n",
    "    logger.info(\"\\nStarting experiments without defense...\")\n",
    "    for percentage in malicious_percentages:\n",
    "        try:\n",
    "            results = run_experiment(\n",
    "                num_clients=num_clients,\n",
    "                malicious_percentage=percentage,\n",
    "                logger=logger,\n",
    "                use_defense=True\n",
    "            )\n",
    "            all_results.extend(results)\n",
    "            logger.info(f\"Completed experiment with {percentage*100}% malicious clients (defense OFF)\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in experiment with {percentage*100}% malicious clients: {str(e)}\")\n",
    "    \n",
    "    return all_results\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedd2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
