{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-04 08:58:00,595 - INFO - \n",
      "=== Testing MUDHOG Defense ===\n",
      "2025-03-04 08:58:00,595 - INFO - \n",
      "=== Testing MUDHOG Defense ===\n",
      "2025-03-04 08:58:00,595 - INFO - \n",
      "=== Testing MUDHOG Defense ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 323\u001b[0m\n\u001b[1;32m    320\u001b[0m     plot_results(results)\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 323\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 315\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pct \u001b[38;5;129;01min\u001b[39;00m malicious_pcts:\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefense\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[3], line 270\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(defense_type, malicious_pct, logger)\u001b[0m\n\u001b[1;32m    268\u001b[0m model \u001b[38;5;241m=\u001b[39m CIFAR10CNN()\n\u001b[1;32m    269\u001b[0m server \u001b[38;5;241m=\u001b[39m Server(model, clients, defense_type\u001b[38;5;241m=\u001b[39mdefense_type)\n\u001b[0;32m--> 270\u001b[0m backdoor_sr, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_round\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdefense_type\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Malicious: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_malicious\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m            \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccess Rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackdoor_sr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% | \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m            \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetection Rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mmetrics\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m0\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefense\u001b[39m\u001b[38;5;124m'\u001b[39m: defense_type,\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmalicious\u001b[39m\u001b[38;5;124m'\u001b[39m: num_malicious,\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuccess_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: backdoor_sr,\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdetection_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    281\u001b[0m }\n",
      "Cell \u001b[0;32mIn[3], line 217\u001b[0m, in \u001b[0;36mServer.train_round\u001b[0;34m(self, local_epochs)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m client \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclients:\n\u001b[1;32m    216\u001b[0m     set_model_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, global_params)\n\u001b[0;32m--> 217\u001b[0m     client_updates\u001b[38;5;241m.\u001b[39mappend(\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_epochs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    219\u001b[0m aggregated_params, metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate(client_updates)\n\u001b[1;32m    220\u001b[0m set_model_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, aggregated_params)\n",
      "Cell \u001b[0;32mIn[3], line 98\u001b[0m, in \u001b[0;36mClient.train\u001b[0;34m(self, model, epochs, batch_size)\u001b[0m\n\u001b[1;32m     96\u001b[0m         output \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m     97\u001b[0m         loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(output, target)\n\u001b[0;32m---> 98\u001b[0m         \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {name: param\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mstate_dict()\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/Desktop/envs/fedd2/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/envs/fedd2/lib/python3.12/site-packages/torch/autograd/__init__.py:340\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    331\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    332\u001b[0m     (inputs,)\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, (torch\u001b[38;5;241m.\u001b[39mTensor, graph\u001b[38;5;241m.\u001b[39mGradientEdge))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[1;32m    337\u001b[0m )\n\u001b[1;32m    339\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[0;32m--> 340\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[0;32m~/Desktop/envs/fedd2/lib/python3.12/site-packages/torch/autograd/__init__.py:95\u001b[0m, in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m     93\u001b[0m new_grads: List[_OptionalTensor] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m out, grad \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(outputs, grads):\n\u001b[0;32m---> 95\u001b[0m     out \u001b[38;5;241m=\u001b[39m cast(\u001b[43mUnion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGradientEdge\u001b[49m\u001b[43m]\u001b[49m, out)\n\u001b[1;32m     96\u001b[0m     out_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     out_device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.12/typing.py:395\u001b[0m, in \u001b[0;36m_tp_cache.<locals>.decorator.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 395\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_caches\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# All real errors (not unhashable args) are raised below.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# federated_defenses.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.feature import hog\n",
    "from torchvision import datasets, transforms\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model Architecture\n",
    "class CIFAR10CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR10CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def get_model_params(model):\n",
    "    return {name: param.clone() for name, param in model.state_dict().items()}\n",
    "\n",
    "def set_model_params(model, params):\n",
    "    model.load_state_dict(params)\n",
    "\n",
    "# Client Implementation\n",
    "class Client:\n",
    "    def __init__(self, client_id, train_data, test_data, is_malicious=False, target_label=None, attack_prob=0.8):\n",
    "        self.client_id = client_id\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.is_malicious = is_malicious\n",
    "        self.target_label = target_label\n",
    "        self.attack_prob = attack_prob\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def add_backdoor_trigger(self, image):\n",
    "        img = deepcopy(image)\n",
    "        h, w = img.shape[1:]\n",
    "        x = np.random.randint(2, w-3)\n",
    "        y = np.random.randint(2, h-3)\n",
    "        trigger_w = np.random.randint(2, 4)\n",
    "        trigger_h = np.random.randint(2, 4)\n",
    "        img[0, y:y+trigger_h, x-trigger_w:x+trigger_w] = 1.0\n",
    "        img[0, y-trigger_w:y+trigger_w, x:x+trigger_h] = 1.0\n",
    "        return img\n",
    "\n",
    "    def poison_dataset(self):\n",
    "        if not self.is_malicious:\n",
    "            return self.train_data\n",
    "            \n",
    "        poisoned_images = []\n",
    "        poisoned_labels = []\n",
    "        for img, label in self.train_data:\n",
    "            if np.random.random() < 0.5:\n",
    "                img = self.add_backdoor_trigger(img)\n",
    "                label = self.target_label\n",
    "            poisoned_images.append(img)\n",
    "            poisoned_labels.append(label)\n",
    "        return TensorDataset(torch.stack(poisoned_images), torch.tensor(poisoned_labels))\n",
    "\n",
    "    def train(self, model, epochs=1, batch_size=32):\n",
    "        model.train().to(self.device)\n",
    "        attack_this_round = self.is_malicious and np.random.rand() < self.attack_prob\n",
    "        train_data = self.poison_dataset() if attack_this_round else self.train_data\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "        \n",
    "        for _ in range(epochs):\n",
    "            for data, target in train_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = F.nll_loss(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "        return {name: param.clone().detach() for name, param in model.state_dict().items()}\n",
    "\n",
    "# Server with Defense Mechanisms\n",
    "class Server:\n",
    "    def __init__(self, model, clients, defense_type='none', threshold=0.9):\n",
    "        self.model = model\n",
    "        self.clients = clients\n",
    "        self.defense_type = defense_type\n",
    "        self.threshold = threshold\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.malicious_ids = {c.client_id for c in clients if c.is_malicious}\n",
    "\n",
    "    def calculate_metrics(self, detected):\n",
    "        tp = len(detected & self.malicious_ids)\n",
    "        fp = len(detected - self.malicious_ids)\n",
    "        fn = len(self.malicious_ids - detected)\n",
    "        tn = len({c.client_id for c in self.clients}) - tp - fp - fn\n",
    "        return {\n",
    "            'dr': tp/(tp+fn) if (tp+fn) > 0 else 0,\n",
    "            'fpr': fp/(fp+tn) if (fp+tn) > 0 else 0,\n",
    "            'precision': tp/(tp+fp) if (tp+fp) > 0 else 0\n",
    "        }\n",
    "\n",
    "    def fools_gold_defense(self, updates):\n",
    "        vectors = [np.concatenate([p.cpu().numpy().flatten() for p in u.values()]) for u in updates]\n",
    "        sim_matrix = cosine_similarity(vectors)\n",
    "        weights = np.ones(len(updates))\n",
    "        detected = set()\n",
    "        \n",
    "        for i in range(len(updates)):\n",
    "            for j in range(len(updates)):\n",
    "                if i != j and sim_matrix[i][j] > self.threshold:\n",
    "                    weights[i] *= 0.5\n",
    "                    detected.add(self.clients[i].client_id)\n",
    "                    \n",
    "        if weights.sum() > 0:\n",
    "            weights /= weights.sum()\n",
    "        else:\n",
    "            weights = np.ones(len(updates))/len(updates)\n",
    "            \n",
    "        return weights, self.calculate_metrics(detected)\n",
    "\n",
    "    def mudhog_defense(self, updates):\n",
    "        vectors = [np.concatenate([p.cpu().numpy().flatten() for p in u.values()]) for u in updates]\n",
    "        \n",
    "        try:  # Handle potential HOG computation errors\n",
    "            hog_features = [hog(vec.reshape(64,64), orientations=8, pixels_per_cell=(16,16)) \n",
    "                            for vec in vectors]\n",
    "        except:\n",
    "            hog_features = np.random.rand(len(vectors), 128)  # Fallback\n",
    "            \n",
    "        pca = PCA(n_components=5)\n",
    "        reduced = pca.fit_transform(hog_features)\n",
    "        kmeans = KMeans(n_clusters=2).fit(reduced)\n",
    "        cluster_counts = np.bincount(kmeans.labels_)\n",
    "        malicious_cluster = np.argmin(cluster_counts)\n",
    "        detected = {self.clients[i].client_id for i in np.where(kmeans.labels_ == malicious_cluster)[0]}\n",
    "        weights = np.array([0.1 if l == malicious_cluster else 1.0 for l in kmeans.labels_])\n",
    "        weights /= weights.sum()\n",
    "        return weights, self.calculate_metrics(detected)\n",
    "\n",
    "    def contra_defense(self, updates):\n",
    "        vectors = [np.concatenate([p.cpu().numpy().flatten() for p in u.values()]) for u in updates]\n",
    "        sim_matrix = cosine_similarity(vectors)\n",
    "        avg_similarities = np.mean(sim_matrix, axis=1)\n",
    "        contrast_scores = 1 / (1 + np.exp(-10*(avg_similarities - np.median(avg_similarities))))\n",
    "        weights = 1 - contrast_scores\n",
    "        detected = {self.clients[i].client_id for i in np.where(contrast_scores > 0.5)[0]}\n",
    "        \n",
    "        if weights.sum() > 0:\n",
    "            weights /= weights.sum()\n",
    "        else:\n",
    "            weights = np.ones(len(updates))/len(updates)\n",
    "            \n",
    "        return weights, self.calculate_metrics(detected)\n",
    "\n",
    "    def aggregate(self, client_updates):\n",
    "        if self.defense_type == 'fools_gold':\n",
    "            weights, metrics = self.fools_gold_defense(client_updates)\n",
    "        elif self.defense_type == 'mudhog':\n",
    "            weights, metrics = self.mudhog_defense(client_updates)\n",
    "        elif self.defense_type == 'contra':\n",
    "            weights, metrics = self.contra_defense(client_updates)\n",
    "        else:\n",
    "            weights = np.ones(len(client_updates))/len(client_updates)\n",
    "            metrics = None\n",
    "\n",
    "        aggregated_params = {}\n",
    "        for name in client_updates[0]:\n",
    "            aggregated_params[name] = sum(update[name]*weight for update, weight in zip(client_updates, weights))\n",
    "            \n",
    "        return aggregated_params, metrics\n",
    "\n",
    "    def evaluate_backdoor(self, target_label):\n",
    "        self.model.eval()\n",
    "        success = 0\n",
    "        total = 0\n",
    "        \n",
    "        for client in self.clients:\n",
    "            if client.is_malicious:\n",
    "                for data, _ in client.test_data:\n",
    "                    poisoned_data = client.add_backdoor_trigger(data.clone())\n",
    "                    poisoned_data = poisoned_data.unsqueeze(0).to(self.device)\n",
    "                    output = self.model(poisoned_data)\n",
    "                    pred = output.argmax(dim=1)\n",
    "                    success += (pred == target_label).sum().item()\n",
    "                    total += 1\n",
    "                    \n",
    "        return 100.0 * success / total if total > 0 else 0.0\n",
    "\n",
    "    def train_round(self, local_epochs=5):\n",
    "        global_params = get_model_params(self.model)\n",
    "        client_updates = []\n",
    "        \n",
    "        for client in self.clients:\n",
    "            set_model_params(self.model, global_params)\n",
    "            client_updates.append(client.train(self.model, epochs=local_epochs))\n",
    "            \n",
    "        aggregated_params, metrics = self.aggregate(client_updates)\n",
    "        set_model_params(self.model, aggregated_params)\n",
    "        backdoor_sr = self.evaluate_backdoor(target_label=7)\n",
    "        return backdoor_sr, metrics\n",
    "\n",
    "# Experiment Framework\n",
    "def setup_logging():\n",
    "    if not os.path.exists('logs'):\n",
    "        os.makedirs('logs')\n",
    "        \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    handler = logging.FileHandler(f'logs/experiment_{timestamp}.log')\n",
    "    handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "    logger.addHandler(handler)\n",
    "    \n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "def load_and_split_data(num_clients):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    ])\n",
    "    \n",
    "    train_set = datasets.CIFAR10('./data', train=True, download=True, transform=transform)\n",
    "    test_set = datasets.CIFAR10('./data', train=False, transform=transform)\n",
    "    \n",
    "    client_train = random_split(train_set, [len(train_set)//num_clients]*num_clients)\n",
    "    client_test = random_split(test_set, [len(test_set)//num_clients]*num_clients)\n",
    "    \n",
    "    return client_train, client_test\n",
    "\n",
    "def run_experiment(defense_type, malicious_pct, logger):\n",
    "    num_clients = 20\n",
    "    client_train, client_test = load_and_split_data(num_clients)\n",
    "    num_malicious = int(num_clients * malicious_pct)\n",
    "    \n",
    "    clients = [\n",
    "        Client(i, client_train[i], client_test[i],\n",
    "              is_malicious=(i < num_malicious), target_label=7)\n",
    "        for i in range(num_clients)\n",
    "    ]\n",
    "    \n",
    "    model = CIFAR10CNN()\n",
    "    server = Server(model, clients, defense_type=defense_type)\n",
    "    backdoor_sr, metrics = server.train_round()\n",
    "    \n",
    "    logger.info(f\"{defense_type.upper()} | Malicious: {num_malicious} | \"\n",
    "               f\"Success Rate: {backdoor_sr:.2f}% | \"\n",
    "               f\"Detection Rate: {metrics['dr']*100 if metrics else 0:.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        'defense': defense_type,\n",
    "        'malicious': num_malicious,\n",
    "        'success_rate': backdoor_sr,\n",
    "        'detection_rate': metrics['dr'] if metrics else 0\n",
    "    }\n",
    "\n",
    "def plot_results(results):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    defenses = ['none', 'fools_gold', 'mudhog', 'contra']\n",
    "    colors = ['red', 'blue', 'green', 'purple']\n",
    "    markers = ['x', 'o', '^', 's']\n",
    "    \n",
    "    for defense, color, marker in zip(defenses, colors, markers):\n",
    "        defense_data = [r for r in results if r['defense'] == defense]\n",
    "        x = [d['malicious'] for d in defense_data]\n",
    "        y = [d['success_rate'] for d in defense_data]\n",
    "        plt.plot(x, y, f'{color}{marker}--', linewidth=2, markersize=10, label=defense)\n",
    "    \n",
    "    plt.xlabel('Number of Malicious Clients', fontsize=12)\n",
    "    plt.ylabel('Backdoor Attack Success Rate (%)', fontsize=12)\n",
    "    plt.title('Defense Mechanism Comparison', fontsize=14)\n",
    "    plt.xticks([2, 3, 4, 5])\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('defense_comparison.png')\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    logger = setup_logging()\n",
    "    results = []\n",
    "    defenses = [ 'mudhog',  'fools_gold', 'contra']\n",
    "    malicious_pcts = [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3,0.35,  0.4,0.45,  0.5]\n",
    "    \n",
    "    for defense in defenses:\n",
    "        logger.info(f\"\\n=== Testing {defense.upper()} Defense ===\")\n",
    "        for pct in malicious_pcts:\n",
    "            try:\n",
    "                result = run_experiment(defense, pct, logger)\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in {defense} {pct}: {str(e)}\")\n",
    "    \n",
    "    plot_results(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-04 08:46:54,967 - INFO - \n",
      "=== Testing NONE Defense ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 410\u001b[0m\n\u001b[1;32m    407\u001b[0m     plot_results(results)\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 410\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 402\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pct \u001b[38;5;129;01min\u001b[39;00m malicious_pcts:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 402\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefense\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    403\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[1], line 357\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(defense_type, malicious_pct, logger)\u001b[0m\n\u001b[1;32m    355\u001b[0m model \u001b[38;5;241m=\u001b[39m CIFAR10CNN()\n\u001b[1;32m    356\u001b[0m server \u001b[38;5;241m=\u001b[39m Server(model, clients, defense_type\u001b[38;5;241m=\u001b[39mdefense_type)\n\u001b[0;32m--> 357\u001b[0m backdoor_sr, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_round\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdefense_type\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Malicious: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_malicious\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    360\u001b[0m            \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccess Rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackdoor_sr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% | \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    361\u001b[0m            \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetection Rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mmetrics\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m0\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefense\u001b[39m\u001b[38;5;124m'\u001b[39m: defense_type,\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmalicious\u001b[39m\u001b[38;5;124m'\u001b[39m: num_malicious,\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuccess_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: backdoor_sr,\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdetection_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    368\u001b[0m }\n",
      "Cell \u001b[0;32mIn[1], line 304\u001b[0m, in \u001b[0;36mServer.train_round\u001b[0;34m(self, local_epochs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m client \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclients:\n\u001b[1;32m    303\u001b[0m     set_model_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, global_params)\n\u001b[0;32m--> 304\u001b[0m     client_updates\u001b[38;5;241m.\u001b[39mappend(\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_epochs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    306\u001b[0m aggregated_params, metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate(client_updates)\n\u001b[1;32m    307\u001b[0m set_model_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, aggregated_params)\n",
      "Cell \u001b[0;32mIn[1], line 92\u001b[0m, in \u001b[0;36mClient.train\u001b[0;34m(self, model, epochs, batch_size)\u001b[0m\n\u001b[1;32m     89\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 92\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/envs/fedd2/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/Desktop/envs/fedd2/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Desktop/envs/fedd2/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/Desktop/envs/fedd2/lib/python3.12/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/Desktop/envs/fedd2/lib/python3.12/site-packages/torchvision/datasets/cifar.py:119\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    116\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/Desktop/envs/fedd2/lib/python3.12/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/Desktop/envs/fedd2/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/envs/fedd2/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/envs/fedd2/lib/python3.12/site-packages/torchvision/transforms/transforms.py:269\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstd \u001b[38;5;241m=\u001b[39m std\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minplace \u001b[38;5;241m=\u001b[39m inplace\n\u001b[0;32m--> 269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mnormalize(tensor, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstd, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minplace)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# federated_defenses.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from torchvision import datasets, transforms\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model Architecture\n",
    "class CIFAR10CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR10CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def get_model_params(model):\n",
    "    return {name: param.clone() for name, param in model.state_dict().items()}\n",
    "\n",
    "def set_model_params(model, params):\n",
    "    model.load_state_dict(params)\n",
    "\n",
    "# Client Implementation\n",
    "class Client:\n",
    "    def __init__(self, client_id, train_data, test_data, is_malicious=False, target_label=None, attack_prob=0.8):\n",
    "        self.client_id = client_id\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.is_malicious = is_malicious\n",
    "        self.target_label = target_label\n",
    "        self.attack_prob = attack_prob\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def add_backdoor_trigger(self, image):\n",
    "        img = deepcopy(image)\n",
    "        h, w = img.shape[1:]\n",
    "        x = np.random.randint(2, w-3)\n",
    "        y = np.random.randint(2, h-3)\n",
    "        trigger_w = np.random.randint(2, 4)\n",
    "        trigger_h = np.random.randint(2, 4)\n",
    "        img[0, y:y+trigger_h, x-trigger_w:x+trigger_w] = 1.0\n",
    "        img[0, y-trigger_w:y+trigger_w, x:x+trigger_h] = 1.0\n",
    "        return img\n",
    "\n",
    "    def poison_dataset(self):\n",
    "        if not self.is_malicious:\n",
    "            return self.train_data\n",
    "            \n",
    "        poisoned_images = []\n",
    "        poisoned_labels = []\n",
    "        for img, label in self.train_data:\n",
    "            if np.random.random() < 0.5:\n",
    "                img = self.add_backdoor_trigger(img)\n",
    "                label = self.target_label\n",
    "            poisoned_images.append(img)\n",
    "            poisoned_labels.append(label)\n",
    "        return TensorDataset(torch.stack(poisoned_images), torch.tensor(poisoned_labels))\n",
    "\n",
    "    def train(self, model, epochs=1, batch_size=32):\n",
    "        model.train().to(self.device)\n",
    "        attack_this_round = self.is_malicious and np.random.rand() < self.attack_prob\n",
    "        train_data = self.poison_dataset() if attack_this_round else self.train_data\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "        \n",
    "        for _ in range(epochs):\n",
    "            for data, target in train_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = F.nll_loss(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "        return {name: param.clone().detach() for name, param in model.state_dict().items()}\n",
    "\n",
    "# Server with Defense Mechanisms\n",
    "class Server:\n",
    "    def __init__(self, model, clients, defense_type='none', l=3, eps=0.5, min_samples=2, k=2, unreliability_threshold=0.3):\n",
    "        self.model = model\n",
    "        self.clients = clients\n",
    "        self.defense_type = defense_type\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.malicious_ids = {c.client_id for c in clients if c.is_malicious}\n",
    "        \n",
    "        # MUD-HoG parameters\n",
    "        self.l = l  # Short-term window size\n",
    "        self.eps = eps  # DBSCAN eps\n",
    "        self.min_samples = min_samples  # DBSCAN min_samples\n",
    "        self.k = k  # K-means clusters\n",
    "        self.unreliability_threshold = unreliability_threshold\n",
    "        \n",
    "        # Gradient history storage\n",
    "        self.short_hog = {c.client_id: [] for c in clients}  # Last l gradients\n",
    "        self.long_hog = {c.client_id: None for c in clients}  # Cumulative gradients\n",
    "\n",
    "    def calculate_metrics(self, detected):\n",
    "        tp = len(detected & self.malicious_ids)\n",
    "        fp = len(detected - self.malicious_ids)\n",
    "        fn = len(self.malicious_ids - detected)\n",
    "        tn = len({c.client_id for c in self.clients}) - tp - fp - fn\n",
    "        return {\n",
    "            'dr': tp/(tp+fn) if (tp+fn) > 0 else 0,\n",
    "            'fpr': fp/(fp+tn) if (fp+tn) > 0 else 0,\n",
    "            'precision': tp/(tp+fp) if (tp+fp) > 0 else 0\n",
    "        }\n",
    "\n",
    "    def fools_gold_defense(self, updates):\n",
    "        vectors = [np.concatenate([p.cpu().numpy().flatten() for p in u.values()]) for u in updates]\n",
    "        sim_matrix = cosine_similarity(vectors)\n",
    "        weights = np.ones(len(updates))\n",
    "        detected = set()\n",
    "        \n",
    "        for i in range(len(updates)):\n",
    "            for j in range(len(updates)):\n",
    "                if i != j and sim_matrix[i][j] > 0.9:  # Fixed threshold\n",
    "                    weights[i] *= 0.5\n",
    "                    detected.add(self.clients[i].client_id)\n",
    "                    \n",
    "        if weights.sum() > 0:\n",
    "            weights /= weights.sum()\n",
    "        else:\n",
    "            weights = np.ones(len(updates))/len(updates)\n",
    "            \n",
    "        return weights, self.calculate_metrics(detected)\n",
    "\n",
    "    def mudhog_defense(self, updates):\n",
    "        client_id_to_idx = {c.client_id: i for i, c in enumerate(self.clients)}\n",
    "        \n",
    "        # Step 1: Detect sign-flipping attackers\n",
    "        short_hogs = []\n",
    "        for c in self.clients:\n",
    "            if len(self.short_hog[c.client_id]) >= 1:\n",
    "                hog = np.mean(self.short_hog[c.client_id], axis=0)\n",
    "            else:\n",
    "                hog = np.concatenate([p.cpu().numpy().flatten() for p in updates[client_id_to_idx[c.client_id]].values()])\n",
    "            short_hogs.append(hog)\n",
    "        \n",
    "        med_short = np.median(short_hogs, axis=0)\n",
    "        sign_flippers = set()\n",
    "        for i, hog in enumerate(short_hogs):\n",
    "            cos_sim = cosine_similarity([hog], [med_short])[0][0]\n",
    "            if cos_sim < 0:\n",
    "                sign_flippers.add(self.clients[i].client_id)\n",
    "        \n",
    "        # Step 2: Detect additive-noise attackers with DBSCAN\n",
    "        remaining = [i for i, c in enumerate(self.clients) if c.client_id not in sign_flippers]\n",
    "        remaining_hogs = [short_hogs[i] for i in remaining]\n",
    "        additive_noise = set()\n",
    "        if len(remaining_hogs) > 0:\n",
    "            db = DBSCAN(eps=self.eps, min_samples=self.min_samples).fit(remaining_hogs)\n",
    "            labels = db.labels_\n",
    "            unique, counts = np.unique(labels[labels != -1], return_counts=True)\n",
    "            if len(unique) > 0:\n",
    "                main_cluster = unique[np.argmax(counts)]\n",
    "                for idx, lbl in enumerate(labels):\n",
    "                    if lbl != main_cluster and lbl != -1:\n",
    "                        additive_noise.add(self.clients[remaining[idx]].client_id)\n",
    "        \n",
    "        # Step 3: Detect targeted attackers with long-term HoG\n",
    "        targeted = set()\n",
    "        remaining_clients = [c for c in self.clients if c.client_id not in sign_flippers | additive_noise]\n",
    "        long_hogs = []\n",
    "        for c in remaining_clients:\n",
    "            if self.long_hog[c.client_id] is not None:\n",
    "                long_hogs.append(self.long_hog[c.client_id])\n",
    "            else:\n",
    "                long_hogs.append(np.concatenate([p.cpu().numpy().flatten() for p in updates[client_id_to_idx[c.client_id]].values()]))\n",
    "        \n",
    "        if len(long_hogs) >= self.k:\n",
    "            kmeans = KMeans(n_clusters=self.k).fit(long_hogs)\n",
    "            cluster_counts = np.bincount(kmeans.labels_)\n",
    "            if len(cluster_counts) >= 2:\n",
    "                malicious_cluster = np.argmin(cluster_counts)\n",
    "                for i, lbl in enumerate(kmeans.labels_):\n",
    "                    if lbl == malicious_cluster:\n",
    "                        targeted.add(remaining_clients[i].client_id)\n",
    "        \n",
    "        # Step 4: Detect unreliable clients\n",
    "        detected = sign_flippers | additive_noise | targeted\n",
    "        remaining = [c for c in self.clients if c.client_id not in detected]\n",
    "        unreliable = set()\n",
    "        if len(remaining) > 0:\n",
    "            remaining_hogs = [short_hogs[client_id_to_idx[c.client_id]] for c in remaining]\n",
    "            med_remaining = np.median(remaining_hogs, axis=0)\n",
    "            for c in remaining:\n",
    "                hog = short_hogs[client_id_to_idx[c.client_id]]\n",
    "                cos_dist = 1 - cosine_similarity([hog], [med_remaining])[0][0]\n",
    "                if cos_dist < self.unreliability_threshold:\n",
    "                    unreliable.add(c.client_id)\n",
    "        \n",
    "        # Calculate weights\n",
    "        weights = []\n",
    "        for c in self.clients:\n",
    "            if c.client_id in detected:\n",
    "                weights.append(0.0)\n",
    "            elif c.client_id in unreliable:\n",
    "                weights.append(0.5)\n",
    "            else:\n",
    "                weights.append(1.0)\n",
    "        weights = np.array(weights)\n",
    "        if weights.sum() == 0:\n",
    "            weights = np.ones(len(weights)) / len(weights)\n",
    "        else:\n",
    "            weights /= weights.sum()\n",
    "        \n",
    "        return weights, self.calculate_metrics(detected)\n",
    "\n",
    "    def contra_defense(self, updates):\n",
    "        vectors = [np.concatenate([p.cpu().numpy().flatten() for p in u.values()]) for u in updates]\n",
    "        sim_matrix = cosine_similarity(vectors)\n",
    "        avg_similarities = np.mean(sim_matrix, axis=1)\n",
    "        contrast_scores = 1 / (1 + np.exp(-10*(avg_similarities - np.median(avg_similarities))))\n",
    "        weights = 1 - contrast_scores\n",
    "        detected = {self.clients[i].client_id for i in np.where(contrast_scores > 0.5)[0]}\n",
    "        \n",
    "        if weights.sum() > 0:\n",
    "            weights /= weights.sum()\n",
    "        else:\n",
    "            weights = np.ones(len(updates))/len(updates)\n",
    "            \n",
    "        return weights, self.calculate_metrics(detected)\n",
    "\n",
    "    def aggregate(self, client_updates):\n",
    "        # Update gradient histories\n",
    "        for client, update in zip(self.clients, client_updates):\n",
    "            grad_vec = np.concatenate([p.cpu().numpy().flatten() for p in update.values()])\n",
    "            # Update short-term history\n",
    "            self.short_hog[client.client_id].append(grad_vec)\n",
    "            if len(self.short_hog[client.client_id]) > self.l:\n",
    "                self.short_hog[client.client_id].pop(0)\n",
    "            # Update long-term history\n",
    "            if self.long_hog[client.client_id] is None:\n",
    "                self.long_hog[client.client_id] = grad_vec.copy()\n",
    "            else:\n",
    "                self.long_hog[client.client_id] += grad_vec\n",
    "        \n",
    "        # Apply defense\n",
    "        if self.defense_type == 'fools_gold':\n",
    "            weights, metrics = self.fools_gold_defense(client_updates)\n",
    "        elif self.defense_type == 'mudhog':\n",
    "            weights, metrics = self.mudhog_defense(client_updates)\n",
    "        elif self.defense_type == 'contra':\n",
    "            weights, metrics = self.contra_defense(client_updates)\n",
    "        else:\n",
    "            weights = np.ones(len(client_updates))/len(client_updates)\n",
    "            metrics = None\n",
    "\n",
    "        # Aggregate parameters\n",
    "        aggregated_params = {}\n",
    "        for name in client_updates[0]:\n",
    "            aggregated_params[name] = sum(update[name] * weight for update, weight in zip(client_updates, weights))\n",
    "            \n",
    "        return aggregated_params, metrics\n",
    "\n",
    "    def evaluate_backdoor(self, target_label):\n",
    "        self.model.eval()\n",
    "        success = 0\n",
    "        total = 0\n",
    "        \n",
    "        for client in self.clients:\n",
    "            if client.is_malicious:\n",
    "                for data, _ in client.test_data:\n",
    "                    poisoned_data = client.add_backdoor_trigger(data.clone())\n",
    "                    poisoned_data = poisoned_data.unsqueeze(0).to(self.device)\n",
    "                    output = self.model(poisoned_data)\n",
    "                    pred = output.argmax(dim=1)\n",
    "                    success += (pred == target_label).sum().item()\n",
    "                    total += 1\n",
    "                    \n",
    "        return 100.0 * success / total if total > 0 else 0.0\n",
    "\n",
    "    def train_round(self, local_epochs=5):\n",
    "        global_params = get_model_params(self.model)\n",
    "        client_updates = []\n",
    "        \n",
    "        for client in self.clients:\n",
    "            set_model_params(self.model, global_params)\n",
    "            client_updates.append(client.train(self.model, epochs=local_epochs))\n",
    "            \n",
    "        aggregated_params, metrics = self.aggregate(client_updates)\n",
    "        set_model_params(self.model, aggregated_params)\n",
    "        backdoor_sr = self.evaluate_backdoor(target_label=7)\n",
    "        return backdoor_sr, metrics\n",
    "\n",
    "# Experiment Framework\n",
    "def setup_logging():\n",
    "    if not os.path.exists('logs'):\n",
    "        os.makedirs('logs')\n",
    "        \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    handler = logging.FileHandler(f'logs/experiment_{timestamp}.log')\n",
    "    handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "    logger.addHandler(handler)\n",
    "    \n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "def load_and_split_data(num_clients):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    ])\n",
    "    \n",
    "    train_set = datasets.CIFAR10('./data', train=True, download=True, transform=transform)\n",
    "    test_set = datasets.CIFAR10('./data', train=False, transform=transform)\n",
    "    \n",
    "    client_train = random_split(train_set, [len(train_set)//num_clients]*num_clients)\n",
    "    client_test = random_split(test_set, [len(test_set)//num_clients]*num_clients)\n",
    "    \n",
    "    return client_train, client_test\n",
    "\n",
    "def run_experiment(defense_type, malicious_pct, logger):\n",
    "    num_clients = 20\n",
    "    client_train, client_test = load_and_split_data(num_clients)\n",
    "    num_malicious = int(num_clients * malicious_pct)\n",
    "    \n",
    "    clients = [\n",
    "        Client(i, client_train[i], client_test[i],\n",
    "              is_malicious=(i < num_malicious), target_label=7)\n",
    "        for i in range(num_clients)\n",
    "    ]\n",
    "    \n",
    "    model = CIFAR10CNN()\n",
    "    server = Server(model, clients, defense_type=defense_type)\n",
    "    backdoor_sr, metrics = server.train_round()\n",
    "    \n",
    "    logger.info(f\"{defense_type.upper()} | Malicious: {num_malicious} | \"\n",
    "               f\"Success Rate: {backdoor_sr:.2f}% | \"\n",
    "               f\"Detection Rate: {metrics['dr']*100 if metrics else 0:.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        'defense': defense_type,\n",
    "        'malicious': num_malicious,\n",
    "        'success_rate': backdoor_sr,\n",
    "        'detection_rate': metrics['dr'] if metrics else 0\n",
    "    }\n",
    "\n",
    "def plot_results(results):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    defenses = ['none', 'fools_gold', 'mudhog', 'contra']\n",
    "    colors = ['red', 'blue', 'green', 'purple']\n",
    "    markers = ['x', 'o', '^', 's']\n",
    "    \n",
    "    for defense, color, marker in zip(defenses, colors, markers):\n",
    "        defense_data = [r for r in results if r['defense'] == defense]\n",
    "        x = [d['malicious'] for d in defense_data]\n",
    "        y = [d['success_rate'] for d in defense_data]\n",
    "        plt.plot(x, y, f'{color}{marker}--', linewidth=2, markersize=10, label=defense)\n",
    "    \n",
    "    plt.xlabel('Number of Malicious Clients', fontsize=12)\n",
    "    plt.ylabel('Backdoor Attack Success Rate (%)', fontsize=12)\n",
    "    plt.title('Defense Mechanism Comparison', fontsize=14)\n",
    "    plt.xticks([2, 3, 4, 5])\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('defense_comparison.png')\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    logger = setup_logging()\n",
    "    results = []\n",
    "    defenses = ['mudhog', 'none', 'fools_gold', 'contra']\n",
    "    malicious_pcts = [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3,0.35,  0.4,0.45,  0.5]\n",
    "    \n",
    "    for defense in defenses:\n",
    "        logger.info(f\"\\n=== Testing {defense.upper()} Defense ===\")\n",
    "        for pct in malicious_pcts:\n",
    "            try:\n",
    "                result = run_experiment(defense, pct, logger)\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in {defense} {pct}: {str(e)}\")\n",
    "    \n",
    "    plot_results(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedd2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
